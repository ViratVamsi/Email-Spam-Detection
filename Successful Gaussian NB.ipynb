{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Implementation for Email Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using self implemented naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set lengths are :  3450 1151\n",
      "Accuracy:  81.49435273675066\n"
     ]
    }
   ],
   "source": [
    "def safe_div(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y\n",
    "\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    " \n",
    "def splitDataset(data,ratio):\n",
    "    dataset=[]\n",
    "    with open(data,'r') as spamfile:\n",
    "        dataset=list(csv.reader(spamfile))\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(57):\n",
    "            dataset[i][j]=float(dataset[i][j])\n",
    "        dataset[i][-1]=int(dataset[i][-1])\n",
    "    trainSize=int(len(dataset)*ratio)\n",
    "    trainSet=[]\n",
    "    copy=list(dataset)\n",
    "    while len(trainSet)<trainSize:\n",
    "        index=random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet,copy]\n",
    "# \n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    " \n",
    "def mean(numbers):\n",
    "    return safe_div(sum(numbers),float(len(numbers)))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = safe_div(sum([pow(x-avg,2) for x in numbers]),float(len(numbers)-1))\n",
    "    return math.sqrt(variance)\n",
    " \n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    " \n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    #in separated lies all mail combined as lists under keys 0 and 1\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "#In summaries all 57 attributes mean and std are present categorized under classValues, and for classValue 1 values are bit greater than for classValues 0\n",
    "    return summaries\n",
    " \n",
    "    \n",
    "# def calculateProbability(x,mean,std):\n",
    "#     exponent=math.exp(-1*math.pow(x-mean,2)/(0.000001+2*math.pow(std,2)))\n",
    "#     return (1/(0.000001+math.sqrt(2*math.pi)*std))*exponent\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-safe_div(math.pow(x-mean,2),(2*math.pow(stdev,2))))\n",
    "    final = safe_div(1 , (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "    return final\n",
    "\n",
    " \n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    #print(probabilities)\n",
    "\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        #print(classValue,'->',probability)\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    " \n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    " \n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    accuracy = safe_div(correct,float(len(testSet))) * 100.0\n",
    "    return accuracy\n",
    "\n",
    "trainSet,testSet=splitDataset('spambase.data',0.75)\n",
    "\n",
    "print('Train and test set lengths are : ',len(trainSet),len(testSet))\n",
    "summaries=summarizeByClass(trainSet)\n",
    "\n",
    "predictions=getPredictions(summaries,testSet)\n",
    "accuracy=getAccuracy(testSet,predictions)\n",
    "# for i in range(len(testSet)):\n",
    "#     print(testSet[i][-1],'->',predictions[i])\n",
    "print('Accuracy: ',accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83       702\n",
      "           1       0.69      0.95      0.80       449\n",
      "\n",
      "    accuracy                           0.81      1151\n",
      "   macro avg       0.83      0.84      0.81      1151\n",
      "weighted avg       0.86      0.81      0.82      1151\n",
      "\n",
      "confusion matrix :\n",
      " [[510 192]\n",
      " [ 21 428]]\n",
      "Spam correctly classified as spam 510\n",
      "Ham being classified as spam 192\n",
      "Ham being classified as not ham 21\n",
      "Spam being classified as Ham 428\n",
      "Accuracy :\n",
      " 0.8149435273675065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "y_test=[]\n",
    "for i in testSet:\n",
    "    y_test.append(i[-1])\n",
    "print(classification_report(y_test,predictions))\n",
    "conf_matrix=confusion_matrix(y_test,predictions)\n",
    "print('confusion matrix :\\n',conf_matrix)\n",
    "print('Spam correctly classified as spam',conf_matrix[0][0])\n",
    "print('Ham being classified as spam',conf_matrix[0][1])\n",
    "print('Ham being classified as not ham',conf_matrix[1][0])\n",
    "print('Spam being classified as Ham',conf_matrix[1][1])\n",
    "print('Accuracy :\\n',accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using sklearn naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       702\n",
      "           1       0.73      0.74      0.74       449\n",
      "\n",
      "    accuracy                           0.79      1151\n",
      "   macro avg       0.78      0.78      0.78      1151\n",
      "weighted avg       0.79      0.79      0.79      1151\n",
      "\n",
      "confusion matrix :\n",
      " [[578 124]\n",
      " [116 333]]\n",
      "Accuracy :\n",
      " 0.7914856646394439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for i in trainSet:\n",
    "    x_train.append(i[:-1])\n",
    "    y_train.append(i[-1])\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "for i in testSet:\n",
    "    x_test.append(i[:-1])\n",
    "    y_test.append(i[-1])\n",
    "\n",
    "classifier=MultinomialNB().fit(x_train,y_train)\n",
    "\n",
    "pred=classifier.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,pred))\n",
    "\n",
    "print('confusion matrix :\\n',confusion_matrix(y_test,pred))\n",
    "print('Accuracy :\\n',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
