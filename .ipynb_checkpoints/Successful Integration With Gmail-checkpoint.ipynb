{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import nltk\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset='textualMailsDataset.csv'\n",
    "df=pd.read_csv(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data by removing stop words and punctuations\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_set=set(stopwords.words('english'))\n",
    "stopwords_set.remove('won')\n",
    "\n",
    "def preProcess(dataset):\n",
    "    with open(dataset,'r') as spam:\n",
    "        data=list(csv.reader(spam))\n",
    "        data=data[1:] #each mail is list of 2 strings.\n",
    "        \n",
    "        #making the data as list of a list with non punct words and list with label [['..','..',...],1/0]\n",
    "        punct=set(string.punctuation)\n",
    "        punct.remove('$')\n",
    "        for email in range(len(data)):\n",
    "            templist=[char for char in data[email][0] if char not in punct]\n",
    "            if(data[email][1]==''):\n",
    "                print(email)\n",
    "            templabel=int(data[email][1])\n",
    "            data[email][0]=''.join(templist)\n",
    "            data[email][1]=templabel\n",
    "        \n",
    "        #removing stop words and numbers from mails\n",
    "        for email in range(len(data)):\n",
    "            tempmail=[]\n",
    "            for word in data[email][0].split():\n",
    "                if(word not in stopwords_set and not word.isnumeric()):\n",
    "                    tempmail.append(word)\n",
    "            data[email][0]=' '.join(tempmail)\n",
    "                    \n",
    "#         for i in range(100):\n",
    "#             print(data[i])\n",
    "        return data\n",
    "\n",
    "data = preProcess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def train_test_split(data,splitRatio):\n",
    "#     trainSet=[]\n",
    "#     testSet=[]\n",
    "#     for i in data:\n",
    "#         if(random.random()<splitRatio):\n",
    "#             trainSet.append(i)\n",
    "#         else:\n",
    "#             testSet.append(i)\n",
    "#     random.shuffle(trainSet)\n",
    "#     random.shuffle(testSet)\n",
    "#     return [trainSet,testSet]\n",
    "\n",
    "def splitinto_labels_attributes(trainset,testset):\n",
    "    #return [trainset[:-1],trainset[-1],testset[:-1],testset[-1]]\n",
    "    x_train=[]\n",
    "    x_test=[]\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    for i in trainset:\n",
    "        x_train.append(i[:-1])\n",
    "        y_train.append(i[-1])\n",
    "    for i in testset:\n",
    "        x_test.append(i[:-1])\n",
    "        y_test.append(i[-1])\n",
    "    return [x_train,y_train,x_test,y_test]\n",
    "\n",
    "# def make_count_vectorizer(data,distinct_words):\n",
    "#     bag=[]\n",
    "#     for email in range(len(data)):\n",
    "#         temp=[0 for i in range(len(distinct_words))]\n",
    "#         i=0\n",
    "#         for word in distinct_words:\n",
    "#             if(word in data[email][0]):\n",
    "#                 temp[i]+=1\n",
    "#             i+=1\n",
    "#         bag.append(temp)\n",
    "#     return bag\n",
    "\n",
    "# def distinctWords(data):\n",
    "#     distinct_words=set()\n",
    "#     for i in range(len(data)):\n",
    "#         for j in range(len(data[i][0])):\n",
    "#             if (data[i][0][j]) not in distinct_words:\n",
    "#                 distinct_words.add(data[i][0][j])\n",
    "#     return distinct_words\n",
    "\n",
    "trainSet=[]\n",
    "testSet=[]\n",
    "data=preProcess(dataset)\n",
    "\n",
    "##############################\n",
    "#######Adding stemming########\n",
    "##############################\n",
    "\n",
    "#data = performStemming(data)\n",
    "\n",
    "# distinct_words=distinctWords(data)\n",
    "\n",
    "# bagOfWords=make_count_vectorizer(data,distinct_words)\n",
    "\n",
    "bow=CountVectorizer(data).fit_transform(df['text'])\n",
    "\n",
    "#x_train,y_train,x_test,y_test=splitinto_labels_attributes(trainSet,testSet)\n",
    "x_train,x_test,y_train,y_test=train_test_split(bow,df['spam'],test_size=0.20,random_state=42)\n",
    "type(bow)\n",
    "#bow.shape  (5728, 37303)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       856\n",
      "           1       0.93      0.69      0.79       290\n",
      "\n",
      "    accuracy                           0.91      1146\n",
      "   macro avg       0.91      0.84      0.87      1146\n",
      "weighted avg       0.91      0.91      0.90      1146\n",
      "\n",
      "confusion matrix :\n",
      " [[840  16]\n",
      " [ 90 200]]\n",
      "Accuracy :\n",
      " 0.9075043630017452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "knn_classifier=KNeighborsClassifier(n_neighbors=5).fit(x_train,y_train)\n",
    "pred=knn_classifier.predict(x_test)\n",
    "print(classification_report(y_test,pred))\n",
    "\n",
    "print('confusion matrix :\\n',confusion_matrix(y_test,pred))\n",
    "print('Accuracy :\\n',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### integration with gmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Define and explain the terms: HPC, HTC, Parallel Computing and\r\n",
      "Distributed Computing.\r\n",
      "2. Define and explain the terms: Cluster Computing, Distributed Systems and\r\n",
      "Cloud Computing.\r\n",
      "3. List and explain different degrees of parallelism.\r\n",
      "4. Differentiate between CPU and GPU. Also explain how GPUs can help CPUs\r\n",
      "in high performance computing.\r\n",
      "5. What are containers? Discuss their advantages and disadvantages.\r\n",
      "6. What are the advantages of using Cloud Computing for business\r\n",
      "applications?\r\n",
      "7. Write brief notes on major categories of P2P network families.\r\n",
      "8. State and explain Amdahl=E2=80=99s Law and Gustafson=E2=80=99s Law.\r\n",
      "9. Discuss about different types of network threats.\r\n",
      "10. Discuss about different mechanisms for reducing energy utilization in\r\n",
      "active servers.\r\n",
      "11. Discuss about Cloud Design Objectives.\r\n",
      "12. Explain the Generic Cloud Architecture\r\n",
      "13. Explain Cloud Architecture Design Challenges\r\n",
      "14. Explain Security  Challenges in Cloud.\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import imaplib\n",
    "import email\n",
    "#from emailmessage import EmailMessage\n",
    "\n",
    "myAcc=os.environ.get('myGmailAddr')\n",
    "passw=os.environ.get('myGmailPass')\n",
    "\n",
    "with imaplib.IMAP4_SSL('imap.gmail.com',993) as con:\n",
    "    con.login(myAcc,passw)\n",
    "    #con.select('\"[Gmail]/Sent Mail\"')\n",
    "    con.select('inbox')\n",
    "    ty,data=con.search(None,'(FROM \"viratvamsi45@gmail.com\")')\n",
    "    mail_ids=data[0].split()\n",
    "    latest_maild=mail_ids[-4]\n",
    "    \n",
    "    ty,data=con.fetch(latest_maild,'(RFC822)')\n",
    "    raw_data=data[0][1]\n",
    "    raw_string=raw_data.decode('utf8')\n",
    "    msg=email.message_from_string(raw_string)\n",
    "    \n",
    "    text_msg=''\n",
    "    #print(msg)\n",
    "    for part in msg.walk():\n",
    "        if(part.get_content_type()=='text/plain'):\n",
    "            text_msg+=part.get_payload()\n",
    "        if(part.get_content_type()!='multipart' and part.get('Content-Disposition') is not None):\n",
    "            continue\n",
    "print(text_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define explain terms HPC HTC Parallel Computing Distributed Computing Define explain terms Cluster Computing Distributed Systems Cloud Computing List explain different degrees parallelism Differentiate CPU GPU Also explain GPUs help CPUs high performance computing What containers Discuss advantages disadvantages What advantages using Cloud Computing business applications Write brief notes major categories P2P network families State explain AmdahlE28099s Law GustafsonE28099s Law Discuss different types network threats Discuss different mechanisms reducing energy utilization active servers Discuss Cloud Design Objectives Explain Generic Cloud Architecture Explain Cloud Architecture Design Challenges Explain Security Challenges Cloud\n",
      "Subject Congratulations You won You won billion euros specify credit card information\n",
      "Subject security alert confirm national credit union information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preProcess_gmails(gmail_list):\n",
    "    #making the data as list of a list with non punct words and list with label [['..','..',...],1/0]\n",
    "    punct=set(string.punctuation)\n",
    "    punct.remove('$')\n",
    "    for email in range(len(gmail_list)):\n",
    "        templist=[char for char in gmail_list[email] if char not in punct]\n",
    "        gmail_list[email]=''.join(templist)\n",
    "\n",
    "    #removing stop words and numbers from mails\n",
    "    for email in range(len(gmail_list)):\n",
    "        tempmail=[]\n",
    "        for word in gmail_list[email].split():\n",
    "            if(word not in stopwords_set and not word.isnumeric()):\n",
    "                tempmail.append(word)\n",
    "        gmail_list[email]=' '.join(tempmail)\n",
    "\n",
    "mails_list=[text_msg,'Subject: Congratulations! You have won: You have won 20 billion euros, specify your credit card information','Subject: security alert - confirm your national credit union information  - - >']\n",
    "labels=[0,1,1]\n",
    "preProcess_gmails(mails_list)\n",
    "for i in range(len(mails_list)):\n",
    "    print(mails_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=CountVectorizer()\n",
    "bag = vec.fit(df['text'])\n",
    "#print(bag.vocabulary_)\n",
    "sample_test_set=bag.transform(mails_list)\n",
    "#print(sample_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "confusion matrix :\n",
      " [[1 0]\n",
      " [0 2]]\n",
      "Accuracy :\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "naive_classifier=MultinomialNB().fit(x_train,y_train)\n",
    "pred=naive_classifier.predict(sample_test_set)\n",
    "print(pred)\n",
    "print(classification_report(labels,pred))\n",
    "\n",
    "print('confusion matrix :\\n',confusion_matrix(labels,pred))\n",
    "print('Accuracy :\\n',accuracy_score(labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
